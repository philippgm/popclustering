{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statistics\n",
    "import os\n",
    "arq = ['clusters/clusters/clusters919probes','clusters/clusters/clusters131probes']\n",
    "grupos = dict()\n",
    "prob = dict()\n",
    "tamanhos = dict()\n",
    "g = dict()\n",
    "total = dict()\n",
    "cdf = dict()\n",
    "for count in range(4):\n",
    "    with open(arq[count],'r') as fp:\n",
    "        grupos[count] = dict()\n",
    "        for linha in fp:\n",
    "            comp = linha.split()\n",
    "            if comp[1] in grupos[count]:\n",
    "                grupos[count][comp[1]] = grupos[count][comp[1]] + 1\n",
    "            else:\n",
    "                grupos[count][comp[1]] = 0\n",
    "                grupos[count][comp[1]] = grupos[count][comp[1]] + 1\n",
    "    print(\"Foi encontrado \"+str(len(grupos[count]))+' '+arq[count])\n",
    "    print(\"O menor cluster possui \" +str(np.min(list(grupos[count].values())))+\" interfaces\")\n",
    "    print(\"O maior cluster possui \" +str(np.max(list(grupos[count].values())))+\" interfaces\")\n",
    "    print(\"A moda possui \" +str(statistics.mode(list(grupos[count].values())))+\" interfaces\")\n",
    "    prob[count] = list()\n",
    "    tamanhos[count] = list()\n",
    "\n",
    "    for j in sorted(set(grupos[count].values())):\n",
    "        a = (j,list(grupos[count].values()).count(j))\n",
    "        prob[count].append(a)\n",
    "        tamanhos[count].append(list(grupos[count].values()).count(j))\n",
    "    print(prob[count])\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    # grupos[count][0]=0\n",
    "    g[count] = sorted(set(grupos[count].values()))\n",
    "    print(g)\n",
    "    # print(tamanhos)\n",
    "    total[count] = len(grupos[count])\n",
    "    cdf[count] = []\n",
    "    cdf[count].append(tamanhos[count][0]/total[count])\n",
    "    for i in range(1,len(tamanhos[count])):\n",
    "        cdf[count].append(cdf[count][i-1]+tamanhos[count][i]/total[count])\n",
    "    print(cdf[count])\n",
    "    plt.figure(2,[10,7.5])\n",
    "    plt.plot(g[count],cdf[count],'b-')\n",
    "    plt.grid()\n",
    "    plt.title(\"CDF dos tamanhos dos PoPs \"+arq[count])\n",
    "    plt.xlabel(\"Tamanho de PoPs\")\n",
    "    plt.ylabel(\"Função cumulativa de PoPs\")\n",
    "    plt.savefig(\"plotCDFs/cdf38probes.jpg\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(2,[10,7.5])\n",
    "plt.grid()\n",
    "plt.title(\"CDF dos tamanhos dos PoPs \")\n",
    "plt.xlabel(\"Tamanho de PoPs (log)\")\n",
    "plt.ylabel(\"Função acumulada de PoPs\")\n",
    "\n",
    "label = [\"142 pontos de medição\",\"996 pontos de medição\"]\n",
    "cores = ['b-','r-']\n",
    "ax = plt.subplot()\n",
    "plt.xscale(\"log\")\n",
    "for i in range(2):\n",
    "    plt.plot(g[i],cdf[i],cores[i],label = label[i])\n",
    "plt.legend()\n",
    "plt.savefig(\"plotCDFsAll150e996.jpg\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from Mylib import Create_output_with_rDNS\n",
    "from Mylib import Clustering_with_rDNS\n",
    "\n",
    "\n",
    "Create_output_with_rDNS(\"clusters/clusters/clusters919probes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Mylib import cluster\n",
    "from Mylib import Create_output_with_rDNS\n",
    "from Mylib import Clustering_with_rDNS\n",
    "import numpy as np\n",
    "clusters = Clustering_with_rDNS(\"clusters/Result_cluster_for_rDNS\")\n",
    "\n",
    "cluster_algo = dict()\n",
    "dns = dict()\n",
    "disc = dict()\n",
    "asf = 1\n",
    "cdf = dict()\n",
    "er = list()\n",
    "arquivos = [\"clusters/clusters/clusters919probesrDNS\",\"clusters/clusters/clusters131probesrDNS\"]\n",
    "for valor in range(2):\n",
    "    print(valor)\n",
    "    with open(\"Similarity_clusters919probesrDNS\",'w') as sim:\n",
    "        with open(arquivos[valor]) as cl:\n",
    "            for i in cl:\n",
    "                f = i.split(' ')\n",
    "                cluster_algo[f[0]] = f[1][2:-2]\n",
    "                dns[f[0]] = f[2][:-1]\n",
    "\n",
    "        for i in range(int(f[1][2:-2])+1):\n",
    "            disc[i] = set()\n",
    "        for j in cluster_algo:\n",
    "            disc[int(cluster_algo[j])].add(j)\n",
    "        gf = list()\n",
    "        for i in range(len(clusters)):\n",
    "            asf = 1\n",
    "            aux = clusters[i].ips[int(len(clusters[i].ips)/2)]\n",
    "            try:\n",
    "                aux1 = int(cluster_algo[aux])\n",
    "            except:\n",
    "                asf = 0\n",
    "            if asf == 1:\n",
    "                aux2 = set(clusters[i].ips) \n",
    "                print(\"\\nAlgoritmo\\n\",file=sim)\n",
    "                rm = set()\n",
    "                p = 1\n",
    "                for count0 in disc[aux1]:\n",
    "                    if len(dns[count0]) == 1:\n",
    "                        rm.add(count0)\n",
    "                    else:\n",
    "                        qwe = 1\n",
    "                        print(f\"{dns[count0]}\",file=sim)\n",
    "                disc[aux1] = disc[aux1].difference(rm)\n",
    "                print(\"\\nGroundtruth\",file=sim)\n",
    "                rm = set()\n",
    "                for count0 in aux2:\n",
    "                    try:\n",
    "                        print(dns[count0],file=sim)\n",
    "                    except:\n",
    "                        rm.add(count0)\n",
    "                aux2 = aux2.difference(rm)\n",
    "                # print(disc[aux1])\n",
    "                print(f\"\\nNúmero de IPs no algoritmo = {len(disc[aux1])}  Número de IPs no GT = {len(aux2)}\",file=sim)\n",
    "                print(f\"Jaccard Index = {len(aux2.intersection(disc[aux1]))/len(aux2.union(disc[aux1]))}\",file=sim)\n",
    "                gf.append(len(aux2.intersection(disc[aux1]))/len(aux2.union(disc[aux1])))\n",
    "        val = list()\n",
    "        total = len(gf)        \n",
    "        for i in sorted(set(gf)):\n",
    "            val.append(gf.count(i))\n",
    "        cdf[valor] = []\n",
    "        cdf[valor].append(val[0]/total)\n",
    "        for i in range(1,len(sorted(set(gf)))):\n",
    "            cdf[valor].append(cdf[valor][i-1]+val[i]/total)\n",
    "        # print(cdf)\n",
    "        \n",
    "        er.append(sorted(set(gf)))\n",
    "        print(sorted(set(gf))[val.index(np.max(val))])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(2,[10,7.5])\n",
    "plt.grid()\n",
    "plt.title(\"CDF Jaccard Index para PoPs \")\n",
    "plt.xlabel(\"Valor Jaccard Index\")\n",
    "plt.ylabel(\"Função acumulada Jaccard Index\")\n",
    "\n",
    "label = [\"996 pontos de medição\",\"142 pontos de medição\"]\n",
    "cores = ['b-','r-']\n",
    "ax = plt.subplot()\n",
    "for i in range(2):\n",
    "    plt.plot(er[i],cdf[i],cores[i],label = label[i])\n",
    "plt.legend()\n",
    "plt.savefig(\"jaccard_index.jpg\")\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sqlite3\n",
    "import gzip\n",
    "import ipaddress\n",
    "import dataclasses\n",
    "from Mylib import *\n",
    "\n",
    "a = measurements()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../Database/logs14-01.txt\",'r') as fl:\n",
    "    for i in fl:\n",
    "        # print(i[:-1],i)\n",
    "        if i[:-1] == \"64.86.21.102\":\n",
    "            vetoraux = fl.readline()\n",
    "            vetoraux = fl.readline()\n",
    "            # vetor = vetoraux.split(\" \")\n",
    "            # vetor.remove(vetor[len(vetor)-1])\n",
    "            with open(\"vetor_de_distancia_para_centroide\",'w') as tx:\n",
    "                # for i,j in enumerate(vetor):\n",
    "                #     # print(f\"<<{len(j)}>>\")\n",
    "                #     p = float(j)\n",
    "                #     if (p < 1):\n",
    "                #         print(j)\n",
    "                #         # print(vetoraux)\n",
    "                #     print(f\"{i} {j}\",file=tx)\n",
    "                print(vetoraux,file=tx)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "import scipy.cluster.hierarchy as shc\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from measurements import measurements\n",
    "\n",
    "%matplotlib inline\n",
    "def HierarchicalClustering(data,n_cluster):\n",
    "\n",
    "    data_scaled = normalize(data)\n",
    "\n",
    "    # plt.figure(figsize=(90, 63))  \n",
    "    # plt.title(\"Dendrograms\")  \n",
    "    # dend = shc.dendrogram(shc.linkage(data_scaled))\n",
    "    \n",
    "    # plt.figure(figsize=(90,63))  \n",
    "    # plt.title(\"Dendrograms\")  \n",
    "    # dend = shc.dendrogram(shc.linkage(data_scaled))\n",
    "    # plt.axhline(y=6, color='r', linestyle='--')\n",
    "    # plt.savefig(\"Dendrograms\"+str(n)+\".jpg\")\n",
    "\n",
    "\n",
    "    cluster = AgglomerativeClustering(n_clusters=n_cluster, affinity='euclidean',linkage= 'average')  \n",
    "    a = cluster.fit_predict(data_scaled)\n",
    "\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import pyasn\n",
    "from Mylib import avg_dist_diff\n",
    "\n",
    "asndb = pyasn.pyasn('../Database/ipasn_20211223.dat')\n",
    "ip = dict()\n",
    "with open (\"rDNSmaster/rDNS.prb\",'r') as fp1:\n",
    "        for j in fp1:\n",
    "            o = j.split(' ,')\n",
    "            ip[o[0]] = o[1]\n",
    "            # break\n",
    "fp2 = dict()            \n",
    "for auxs in a.keys():\n",
    "    if len(a[auxs].keys()) > 250:\n",
    "        asn_value = asndb.lookup(str(ipaddress.IPv4Address(auxs)))[0]\n",
    "        if asn_value not in fp2:\n",
    "            fp2[asn_value] = list()\n",
    "            fp2[asn_value].append(auxs)\n",
    "        else:\n",
    "            fp2[asn_value].append(auxs)\n",
    "print(len(fp2))\n",
    "with open(\"clusters/clusters603probes_400\",'r') as fp2:\n",
    "list_cluster = list()\n",
    "aux = list()\n",
    "count = 0\n",
    "count3 = 0\n",
    "last_cluster = None\n",
    "current_cluster = None\n",
    "aux1 = 0\n",
    "for i in tqdm.tqdm(fp2.keys()):\n",
    "    # print(str(ipaddress.IPv4Address(int(i.split(' ')[0]))))\n",
    "    # c = i.split(' ')\n",
    "    # aux.append(int(c[1]))\n",
    "    # current_cluster = int(c[1])\n",
    "    len_list_cluster = len(fp2[i])\n",
    "    # print(len_list_cluster)\n",
    "    dist = np.zeros((len_list_cluster,len_list_cluster))\n",
    "    for count1 in range(len_list_cluster):\n",
    "        for count2 in range(count1+1,len_list_cluster):\n",
    "            # print(set(a[list_cluster[count1]].keys()))\n",
    "            common_probes = set(a[int(fp2[i][count1])].keys()) & set(a[int(fp2[i][count2])].keys())\n",
    "            if len(common_probes)> 0:\n",
    "                dist[count1][count2] =  avg_dist_diff(a[int(fp2[i][count1])],a[int(fp2[i][count2])],common_probes)\n",
    "            else:\n",
    "                dist[count1][count2] =10\n",
    "            # dist[count2][count1] = dist[count1][count2]\n",
    "    count = 0\n",
    "    # print(dist)\n",
    "    result = HierarchicalClustering(dist,40)\n",
    "    with open(\"result_cluster_hierarchicalduro\",'a') as arquivo:\n",
    "        for each in range(len_list_cluster):\n",
    "            # print(f\"{str(ipaddress.IPv4Address(int(list_cluster[each])))} <<{result[each]}>>\")\n",
    "            g = str(ipaddress.IPv4Address(int(fp2[i][each])))\n",
    "            if g in ip:\n",
    "                print(g+' <<'+str(result[each]+count*40)+'>> '+ip[g][:-1],file=arquivo)\n",
    "            else:\n",
    "                print(g+\" <<\"+str(result[each]) +\">> No rDNS\",file=arquivo)\n",
    " \n",
    "        \n",
    "                \n",
    "                   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip = dict()\n",
    "with open (\"rDNSmaster/rDNS.prb\",'r') as fp1:\n",
    "        for j in fp1:\n",
    "            o = j.split(' ,')\n",
    "            ip[o[0]] = o[1]\n",
    "            # break\n",
    "fp2 = list()            \n",
    "for auxs in a.keys():\n",
    "    if (len(a[auxs].keys()) < 200) & (len(a[auxs].keys()) > 130):\n",
    "        fp2.append(auxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from measurements import measurements\n",
    "import ipaddress\n",
    "import numpy as np\n",
    "from ipaddress import IPv4Address\n",
    "import dataclasses\n",
    "import tqdm\n",
    "import sqlite3\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import pyasn\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class Cluster:\n",
    "    ips: list\n",
    "    src2median: dict\n",
    "    src2dists: dict\n",
    "    asn_value: int\n",
    "\n",
    "    @staticmethod\n",
    "    def new(ip, src2dist,asndb):\n",
    "        # asn_value = asndb.lookup(str(ipaddress.IPv4Address(ip)))[0]\n",
    "        # print(ip,asn_value)\n",
    "        cluster = Cluster([ip], dict(src2dist), defaultdict(list),0)\n",
    "        for src, dist in src2dist.items():\n",
    "            cluster.src2dists[src].append(dist)\n",
    "        return cluster\n",
    "\n",
    "    def add(self, ip, src2dist):\n",
    "        self.ips.append(ip)\n",
    "        for src, dist in src2dist.items():\n",
    "            self.src2dists[src].append(dist)\n",
    "            self.src2median[src] = np.median(self.src2dists[src])\n",
    "            # self.src2median[src] = np.median(self.src2dists[src])[0]\n",
    "    def asn(self):\n",
    "        return self.asn_value\n",
    "a = measurements()\n",
    "\n",
    "# with open(\"clusters/clusters708probes_100_metrica\") as fl:\n",
    "#     clusters = list()\n",
    "#     for i in fl:\n",
    "\n",
    "#         aux =  i.split(\" \")\n",
    "#         ip = int(aux[0])\n",
    "#         # print(ip)\n",
    "#         clusterr = int(aux[1])\n",
    "#         if len(clusters) == clusterr+1:\n",
    "#             clusters[clusterr].add(ip,a[ip])\n",
    "#         else:\n",
    "#             clusters.append(Cluster.new(ip,a[ip],0))\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nessa celula imprime em um arquivo \n",
    "from measurements import avg_dist_diff\n",
    "import tqdm\n",
    "\n",
    "# centroid1 = 689  #tcore2 sanjose\n",
    "# centroid2 = 718  #tcore1 sanjose\n",
    "centroid1 = 3\n",
    "centroid2 = 3\n",
    "common_probes = set(clusters[centroid2].src2median.keys()) & set(clusters[centroid1].src2median.keys())\n",
    "if len(common_probes) > 100:\n",
    "    metric = avg_dist_diff(clusters[centroid1].src2median, clusters[centroid2].src2median, common_probes)\n",
    "    print(metric)\n",
    "common_probes = set(clusters[centroid2].src2median.keys()) & set(clusters[centroid1].src2median.keys())\n",
    "\n",
    "count = 1\n",
    "with open(\"vetor_de_media_distancia_centroide\",\"w\") as flmedia:\n",
    "    for i in common_probes:\n",
    "        print(str(count)+\"\\t\"+str(clusters[centroid1].src2median[i])+\"\\t\"+str(clusters[centroid2].src2median[i])+\"\\t\",file=flmedia)\n",
    "        count +=1\n",
    "print(len(common_probes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from measurements import measurements\n",
    "a = measurements()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nesta celula imprime a distância dos IPs ao centroid do cluster.\n",
    "# O cluster é escolhido atraves do \"index_cluster\".\n",
    "\n",
    "import ipaddress \n",
    "from measurements import measurements\n",
    "from Mylib import avg_dist_diff\n",
    "\n",
    "index_cluster = \"3\"\n",
    "targets = list()\n",
    "with open(\"clusters/clusters815probes_100_metricarDNS\") as flclusters:\n",
    "    for linha in flclusters:\n",
    "        strs = linha.split(\" \")\n",
    "        if (strs[1][2:-2]) == index_cluster:\n",
    "            targets.append(strs[0])\n",
    "            \n",
    "# print(targets)\n",
    "\n",
    "with open(\"vetor_de_distancias_para_centroides_cluster_\"+index_cluster,'w') as fg:\n",
    "    all_probes = set()\n",
    "    # print(targets)\n",
    "    all_probes = set(a[int(ipaddress.IPv4Address(targets[0]))].keys())\n",
    "    print(a[int(ipaddress.IPv4Address(targets[0]))].keys())\n",
    "    for i in targets:\n",
    "        all_probes = all_probes | set(a[int(ipaddress.IPv4Address(i))].keys())\n",
    "    \n",
    "\n",
    "    for count,ips in enumerate(targets):    \n",
    "        fg.write(str(count)+\"=\"+ips+\"\\t\")\n",
    "    fg.write(\"\\n\\n\"\"0    \\t\")\n",
    "    for i in range(len(targets)+1):    \n",
    "        fg.write(str(i)+\"\\t\")\n",
    "    fg.write(\"\\n\")\n",
    "    # str(ipaddress.IPv4Address(i))+\"///\"+\n",
    "    for count,i in enumerate(all_probes):\n",
    "        fg.write(str(i)+\"->  \\t\")\n",
    "        for j in targets:\n",
    "            if i in a[int(ipaddress.IPv4Address(j))]:    \n",
    "                fg.write(str(a[int(ipaddress.IPv4Address(j))][i])+\"\\t\")\n",
    "            else:\n",
    "                fg.write(\"N\"+\"\\t\")\n",
    "        fg.write(\"\\n\")\n",
    "\n",
    "    # for each_target in targets:\n",
    "    #     centroid1 = 3\n",
    "    #     common_probes = set(a[int(ipaddress.IPv4Address(each_target))].keys()) & set(clusters[centroid1].src2median.keys())\n",
    "    #     metric = avg_dist_diff(clusters[centroid1].src2median, a[int(ipaddress.IPv4Address(each_target))], common_probes)\n",
    "    #     print(f\" IP = {each_target}\\t Distância = {metric}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import ipaddress\n",
    "import tqdm\n",
    "from measurements import infer_reverse_hop_distance\n",
    "saida = dict()\n",
    "src = dict()\n",
    "con = sqlite3.connect('../Database/MeasurementAndProbes.db')\n",
    "cur = con.cursor()\n",
    "cur.execute(\"select dst_addr,prb_id,ttl from Results\")\n",
    "res = cur.fetchall()\n",
    "b = 0\n",
    "for linha in tqdm.tqdm(res):\n",
    "    # print(linha)\n",
    "    aux = infer_reverse_hop_distance(linha[2])\n",
    "    if aux != None:\n",
    "        if linha[1] in saida:\n",
    "            saida[linha[1]][int(ipaddress.IPv4Address(linha[0]))] = aux\n",
    "        else:\n",
    "            saida[linha[1]] = dict()\n",
    "            saida[linha[1]][int(ipaddress.IPv4Address(linha[0]))] = aux\n",
    "\n",
    "\n",
    "    b = b +1\n",
    "con.close()\n",
    "con = sqlite3.connect('../Database/MeasurementAndProbesbo.db')\n",
    "cur = con.cursor()\n",
    "cur.execute(\"select dst_addr,prb_id,ttl from Results\")\n",
    "res = cur.fetchall()\n",
    "b = 0\n",
    "for linha in tqdm.tqdm(res):\n",
    "    # print(linha)\n",
    "    aux = infer_reverse_hop_distance(linha[2])\n",
    "    if aux != None:\n",
    "        if linha[1] in saida:\n",
    "            saida[linha[1]][int(ipaddress.IPv4Address(linha[0]))] = aux\n",
    "        else:\n",
    "            saida[linha[1]] = dict()\n",
    "            saida[linha[1]][int(ipaddress.IPv4Address(linha[0]))] = aux\n",
    "\n",
    "\n",
    "    b = b +1\n",
    "con.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_probes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "813\n",
      "94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 813/813 [00:00<00:00, 1700.08it/s]\n",
      "100%|██████████| 813/813 [00:00<00:00, 1293124.44it/s]\n"
     ]
    }
   ],
   "source": [
    "lista_sondas_remove = dict()\n",
    "print(len(all_probes))\n",
    "print(len(targets))\n",
    "for i in tqdm.tqdm(all_probes):\n",
    "    lista_sondas_remove[i] = set()\n",
    "    for j in targets:\n",
    "        # print(saida.keys())\n",
    "        if int(ipaddress.IPv4Address(j)) in saida[i].keys():\n",
    "            lista_sondas_remove[i].add(saida[i][int(ipaddress.IPv4Address(j))])\n",
    "# print(lista_sondas_remove)\n",
    "\n",
    "lista_remove = set()\n",
    "for i in tqdm.tqdm(all_probes):\n",
    "    if len(lista_sondas_remove[i]) <= 2:\n",
    "        lista_remove.add(i)\n",
    "# # with open(\"probes_removed2\",'w') as flprobesrm:\n",
    "# #     for i in lista_remove:\n",
    "# #         print(ipaddress.IPv4Address(i),file=flprobesrm)\n",
    "# len(lista_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{4101, 18438, 53260, 16399, 53266, 16404, 28698, 4127, 16416, 32, 32805, 38, 40, 10281, 2044, 45, 32816, 14387, 4148, 10293, 28726, 16438, 4155, 4158, 18494, 28755, 32863, 95, 26722, 10338, 18540, 10350, 30833, 22642, 51315, 28794, 28796, 126, 127, 51329, 53379, 34948, 26758, 34951, 6295, 20639, 10403, 53415, 18599, 176, 30896, 14520, 51388, 22720, 16583, 26823, 35016, 12501, 16604, 24804, 24806, 4335, 18671, 14587, 20733, 22782, 2305, 53509, 22789, 53516, 53517, 12558, 22801, 22802, 20756, 28949, 26900, 53527, 2326, 28956, 31006, 35103, 35105, 12583, 53545, 51497, 31024, 33076, 1001780, 10554, 2374, 24903, 329, 12617, 24907, 10587, 16732, 14694, 31079, 20843, 12652, 22894, 2416, 6517, 4473, 22908, 383, 385, 4482, 16785, 22945, 24999, 35239, 14761, 10667, 12721, 20913, 20916, 4534, 4539, 33213, 16831, 14785, 33227, 33230, 20948, 20955, 4575, 31201, 2553, 4602, 33282, 12803, 21003, 23058, 1002006, 55833, 2590, 29215, 18975, 53793, 4653, 35375, 4659, 14899, 12857, 35393, 51782, 31302, 12873, 33356, 12877, 53838, 12890, 29287, 4712, 12904, 14955, 31342, 29304, 33403, 12933, 4741, 33415, 646, 1002118, 19078, 651, 17036, 2697, 35469, 656, 12944, 1002133, 2711, 10904, 27289, 19103, 33442, 4783, 17081, 27323, 29376, 2758, 29385, 15053, 29393, 29395, 21204, 25313, 21221, 35558, 4842, 750, 51952, 13054, 15105, 51975, 11016, 51984, 25362, 27411, 13077, 6944, 21283, 11046, 11050, 29490, 52031, 842, 33614, 13138, 851, 50002, 50007, 33626, 25440, 21345, 54113, 23392, 19298, 50023, 52072, 50025, 50035, 21364, 13177, 50042, 50043, 15226, 31612, 29568, 21377, 2944, 23424, 901, 25486, 13200, 2968, 11162, 52123, 928, 52128, 25508, 29606, 21416, 29610, 952, 19393, 50143, 11243, 52209, 1018, 11266, 17414, 31750, 21513, 21514, 11274, 33804, 19473, 27668, 11289, 25628, 3103, 33840, 29748, 3128, 29753, 21566, 21568, 21569, 31809, 50243, 27724, 52305, 17490, 29782, 11350, 25697, 33890, 1123, 13411, 19555, 21609, 52329, 15467, 33901, 50289, 52338, 13441, 52353, 13443, 19591, 19597, 19599, 27797, 21658, 13469, 21662, 1000610, 13477, 19624, 11440, 31927, 19641, 52413, 17601, 19650, 21699, 19651, 50379, 1232, 19667, 52440, 19675, 11484, 11487, 13539, 34020, 3307, 1261, 54513, 19702, 25850, 3326, 3327, 19714, 19717, 27912, 11529, 15633, 27925, 15644, 25885, 11550, 50476, 27952, 3379, 50488, 1336, 21821, 1344, 32064, 3395, 50502, 17739, 32075, 32096, 11621, 50534, 50535, 19817, 34154, 25965, 32111, 11633, 15732, 34168, 15736, 19834, 13691, 15743, 19843, 17797, 32136, 1419, 30097, 32150, 30104, 30109, 19877, 17833, 32169, 11691, 32179, 28086, 32186, 1477, 21957, 3528, 19926, 26083, 11747, 52708, 19956, 50684, 17918, 3596, 11794, 50710, 17950, 24096, 20004, 34343, 50728, 15928, 3649, 30278, 17998, 3670, 52827, 28272, 30326, 32375, 52861, 13955, 50823, 18062, 50831, 22158, 13972, 34453, 50840, 30370, 3752, 28331, 32430, 52913, 22200, 14012, 52930, 32453, 28369, 14038, 11990, 16087, 50913, 52965, 12017, 50943, 50954, 20234, 28431, 50961, 12049, 28447, 22310, 14122, 14123, 3884, 22320, 53046, 51013, 28487, 14154, 32592, 12118, 14175, 34658, 16228, 22377, 16234, 18288, 10099, 51065, 32633, 26496, 51072, 3977, 34698, 20363, 26518, 12185, 14242, 14244, 18355, 51127, 24505, 18366, 20415, 10179, 32710, 32712, 4040, 14285, 14291, 34775, 10203, 32731, 10210, 51171, 20451, 32751, 1001461, 53244}\n"
     ]
    }
   ],
   "source": [
    "print(lista_remove)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
